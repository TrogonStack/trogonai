//! Demo of streaming functionality without requiring a real Telegram bot
//!
//! This simulates both the agent sending chunks and the bot processing them

use std::time::Duration;
use tokio::time::{sleep, Instant};

struct MockStreamingProcessor {
    message_id: Option<i32>,
    last_edit: Instant,
    edit_count: u32,
}

impl MockStreamingProcessor {
    fn new() -> Self {
        Self {
            message_id: None,
            last_edit: Instant::now(),
            edit_count: 0,
        }
    }

    async fn process_chunk(&mut self, text: &str, is_final: bool) {
        const MIN_EDIT_INTERVAL: Duration = Duration::from_millis(1000);

        if let Some(msg_id) = self.message_id {
            // Editing existing message
            let time_since_last = self.last_edit.elapsed();

            if time_since_last < MIN_EDIT_INTERVAL {
                let wait_time = MIN_EDIT_INTERVAL - time_since_last;
                println!("  â±ï¸  Rate limiting: waiting {:?} before edit", wait_time);
                sleep(wait_time).await;
            }

            self.edit_count += 1;
            println!(
                "  âœï¸  Edit #{}: Message {} â†’ \"{}\"{}",
                self.edit_count,
                msg_id,
                if text.len() > 60 {
                    format!("{}...", &text[..60])
                } else {
                    text.to_string()
                },
                if is_final { " (FINAL)" } else { "" }
            );

            self.last_edit = Instant::now();

            if is_final {
                println!("  ğŸ Streaming complete! Cleaning up tracking...");
                self.message_id = None;
                self.edit_count = 0;
            }
        } else {
            // Creating new message
            self.message_id = Some(42_i32); // Mock message ID
            self.last_edit = Instant::now();

            println!(
                "  ğŸ“¤ New message {}: \"{}\"",
                self.message_id.unwrap(),
                if text.len() > 60 {
                    format!("{}...", &text[..60])
                } else {
                    text.to_string()
                }
            );

            if is_final {
                println!("  â„¹ï¸  Message was final on first send (no more updates)");
            }
        }
    }
}

#[tokio::main]
async fn main() {
    println!("ğŸ¬ TrogonAI Streaming Demo");
    println!("==========================\n");

    let mut processor = MockStreamingProcessor::new();

    // Simulate LLM generating a response in chunks
    let response_chunks = vec![
        ("Hello! ", false),
        ("I'm an AI assistant ", false),
        ("powered by TrogonAI. ", false),
        ("I can stream my responses ", false),
        ("progressively, ", false),
        ("just like ChatGPT! ", false),
        ("This demonstrates:\n\n", false),
        ("âœ“ Rate limiting (1 edit/second)\n", false),
        ("âœ“ Message tracking by session\n", false),
        ("âœ“ Progressive edits\n", false),
        ("âœ“ Proper cleanup with is_final flag\n\n", false),
        ("All working perfectly! ğŸš€", true),
    ];

    println!("ğŸ“ Simulating LLM streaming response...\n");

    let mut accumulated = String::new();
    let start_time = Instant::now();

    for (i, (chunk, is_final)) in response_chunks.iter().enumerate() {
        accumulated.push_str(chunk);

        println!("ğŸ“Š Chunk {}/{} received", i + 1, response_chunks.len());

        processor.process_chunk(&accumulated, *is_final).await;

        if !is_final {
            // Simulate time between LLM chunks
            sleep(Duration::from_millis(200)).await;
        }

        println!();
    }

    let total_time = start_time.elapsed();

    println!("âœ… Demo Complete!\n");
    println!("ğŸ“Š Statistics:");
    println!("  â€¢ Total chunks processed: {}", response_chunks.len());
    println!("  â€¢ Total edits performed: {}", processor.edit_count);
    println!("  â€¢ Time elapsed: {:.2}s", total_time.as_secs_f64());
    println!("  â€¢ Final message length: {} chars", accumulated.len());
    println!("\nğŸ¯ Features Demonstrated:");
    println!("  âœ“ Initial message creation");
    println!("  âœ“ Progressive message editing");
    println!("  âœ“ Rate limiting (1 edit/second minimum)");
    println!("  âœ“ Message tracking");
    println!("  âœ“ Proper cleanup on final chunk");
    println!("\nğŸ’¡ In production:");
    println!("  â€¢ This would send actual Telegram API calls");
    println!("  â€¢ Messages would appear in Telegram chat");
    println!("  â€¢ Rate limiting prevents API throttling");
    println!("  â€¢ Retry logic handles transient failures");
}
